{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e871ce00",
   "metadata": {},
   "source": [
    "## Install `PADL` and `sentencepiece`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install git+https://github.com/lf1-io/padl.git\n",
    "\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f55ea",
   "metadata": {},
   "source": [
    "## Download `Sentiment140` dataset with 1.6 million tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "!mkdir -p data\n",
    "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
    "!unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642e44f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc08821",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Padl\n",
    "This notebook implements and trains a Sentiment Monitor using `padl`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb1698",
   "metadata": {},
   "source": [
    "We import `padl` along all the needed libraries and define some required constants for the model. From `padl` we import the elements `transform`, `batch`, `unbatch`, `same` and `identity`:\n",
    "- `transform`: Any callable class implementing `__call__` or any class inheriting `torch.nn.Module` (and implementing `forward`) can become a `Transform` using the `transform` decorator. \n",
    "\n",
    "- `batch`: Stands for `padl.transforms.Batchify`, which determines where the dataloader is called, and the batchs are created sent to the gpu.\n",
    "\n",
    "- `unbatch`: Stands for `padl.transforms.Unbatchify`, which unbatches the output of the neural network and indicates the beginning of the postprocess stage, carried out on the cpu.\n",
    "\n",
    "- `same`: Operator for calling methods or attributes of the object passed through it. For example: `same.count(5)([5, 7, 8, 5, 5) # outputs 3`\n",
    "\n",
    "- `identity`: Stands for `padl.transforms.Identity()`, which is the Identity transform.\n",
    "\n",
    "For our model we will also use the some global variables: `VOCAB_SIZE`, `TRAIN_TEST_SPLIT`, `EMB_DIM`, `RNN_HIDDEN_SIZE`, `DECODER_HIDDEN`, `PADDING_PERCENTILE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import uuid\n",
    "import numpy\n",
    "import pandas\n",
    "import sentencepiece\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import padl\n",
    "from padl import transform, batch, unbatch, same, identity\n",
    "\n",
    "VOCAB_SIZE = 5000 # Size of the vocabulary used by our tokenizer  \n",
    "TRAIN_TEST_SPLIT = 10000 # Number of components of each embedding vector\n",
    "EMB_DIM = 64 # Number of components of each embedding vector\n",
    "RNN_HIDDEN_SIZE = 1024 # Hidden size of our recurrent layer\n",
    "DECODER_HIDDEN = 64 # Number of hidden dimensions in the dense layers after the rnn\n",
    "PADDING_PERCENTILE = 99 # Percentile of datapoints at which we want to truncate our padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b4c00",
   "metadata": {},
   "source": [
    "### The data\n",
    "The dataset used in this notebook is `Sentiment140`, which contains 1.6 million of tweets classified as negative (0) or positive (4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca88ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\n",
    "    \"data/training.1600000.processed.noemoticon.csv\",\n",
    "    header=None,\n",
    "    encoding='latin-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4154e",
   "metadata": {},
   "source": [
    "Let's check out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facedc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be422b8",
   "metadata": {},
   "source": [
    "We only need the first (label) and the last (text) columns. We keep, rename them and split in train and valid sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=[1, 2, 3, 4], axis=1).rename(columns={0: 'label', 5: 'text'})\n",
    "data['label'] = data['label'].apply(lambda x: int(x/4))\n",
    "data_list = list(zip(data['text'], data['label']))\n",
    "random.shuffle(data_list)\n",
    "train_data = data_list[:-TRAIN_TEST_SPLIT]\n",
    "valid_data = data_list[-TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7403da77",
   "metadata": {},
   "source": [
    "We dump a text file with one sentence on each line that will be used for training our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'w') as f:\n",
    "    f.writelines(data['text'][:-TRAIN_TEST_SPLIT].apply(lambda x: x + '\\n').tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da9177",
   "metadata": {},
   "source": [
    "### Creating the Transforms\n",
    "It is time to proceed to define and instantiate the `Transform` we are going to use in our model. With `padl` this is very easy! We write functions and classes implementing a `__call__` method or a `forward` if they  inherit `torch.nn.Module`, and we add the `@transform` decorator. Then, they will be ready to use the `padl` features like saving, composing, applying... As simple as that!\n",
    "\n",
    "We create the following ones:\n",
    "- `Bpe`: Consists of a tokenizer based on the byte pair encoding algorithm and uses the `sentencepiece` package.\n",
    "- `Pad_Seq`: Pads our sentences so they have the same sequence length and can be processed into batches. In our case, we choose a padding length at the 99th percentile of lengths of the samples.\n",
    "- `Embedding`: Our tokens embedder.\n",
    "- `MyNN`: Class containing our architecture.\n",
    "- `classify`: postprocess the output of the neural network.\n",
    "- `to_tensor`: converts the input to a `torch.Tensor`.\n",
    "- `loss_function`: loss function used on the training, which is the CrossEntropyLoss.\n",
    "- `norm`: computes probability values using a softmax function. This is used in the infer mode to get an idea of the probabilities of positiveness and negativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform\n",
    "class Bpe:\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        self.vocab_size = None\n",
    "        self.dic = None\n",
    "        self.model_prefix = str(uuid.uuid4())\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self._model.encode_as_ids(x)\n",
    "    \n",
    "    def fit(self, corpus_file):\n",
    "        sentencepiece.SentencePieceTrainer.Train(\n",
    "            f'--input={corpus_file} '\n",
    "            f'--model_prefix={self.model_prefix} '\n",
    "            f'--vocab_size={VOCAB_SIZE} '\n",
    "            f'--character_coverage={1.0} '\n",
    "            '--model_type=bpe '\n",
    "        )\n",
    "        self._model = sentencepiece.SentencePieceProcessor()\n",
    "        self._model.Load(f'{self.model_prefix}.model')\n",
    "        self.vocab_size = self._model.vocab_size()\n",
    "        self.dic = {i:self._model.decode([i]) for i in range(self.vocab_size)}\n",
    "        with open(f'{self.model_prefix}.model', 'rb') as f:\n",
    "            self._content = f.read()\n",
    "        os.remove(f'{self.model_prefix}.model')\n",
    "        os.remove(f'{self.model_prefix}.vocab')\n",
    "    \n",
    "    def post_load(self, path, i):\n",
    "        self._model = sentencepiece.SentencePieceProcessor()\n",
    "        self._model.Load(str(path / f'{i}.model'))\n",
    "    \n",
    "    def pre_save(self, path, i):\n",
    "        with open(path / f'{i}.model', 'wb') as f:\n",
    "            f.write(self._content)\n",
    "\n",
    "\n",
    "@transform\n",
    "class Pad_Seq:\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __call__(self, seq):\n",
    "        if len(seq) < self.seq_len:\n",
    "            return seq + [2 for i in range(len(seq), self.seq_len)], [len(seq)]\n",
    "        return seq[:self.seq_len], [self.seq_len] \n",
    "\n",
    "\n",
    "@transform\n",
    "class MyNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, decoder_hidden, emb_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=self.hidden_size, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.lin1 = torch.nn.Linear(self.hidden_size, self.decoder_hidden)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.lin2 = torch.nn.Linear(self.decoder_hidden, 2)\n",
    "    \n",
    "    def forward(self, x, lengths=None):\n",
    "        out, state = self.lstm(x)\n",
    "        if self.pd_mode != 'infer':\n",
    "            output = [sentence[length.item() - 1 , :] for sentence, length in zip(out, lengths)]\n",
    "            output = torch.stack(output)\n",
    "        if self.pd_mode == 'infer':\n",
    "            output = state[0].squeeze(0)\n",
    "        dec = self.lin1(output)\n",
    "        dec = self.act(dec)\n",
    "        return self.lin2(dec)\n",
    "    \n",
    "\n",
    "@transform\n",
    "def classify(x):\n",
    "    negative_score = x[0].item()\n",
    "    positive_score = x[1].item()\n",
    "    if positive_score > 0.6:\n",
    "        category = 'Positive'\n",
    "    elif 0.4 < positive_score <= 0.6:\n",
    "        category = 'Neutral'\n",
    "    elif 0.4 <= positive_score:\n",
    "        category = 'Negative'\n",
    "    return {'Negativeness': round(negative_score, 2),\n",
    "            'Positiveness': round(positive_score, 2), 'Sentiment': category}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e9dae",
   "metadata": {},
   "source": [
    "Initialize the Byte Pair Encoder and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d706b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = Bpe()\n",
    "bpe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee2568",
   "metadata": {},
   "source": [
    "Fit the Byte Pair Encoder on our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48043d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe.fit('corpus.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09d276",
   "metadata": {},
   "source": [
    "Choose a padding length and define the remaining components of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = [train_data[i][0] for i in numpy.random.permutation(len(train_data))[:10000]]\n",
    "len_list = [len(bpe(sent)) for sent in random_sample]\n",
    "seq_len = int(numpy.quantile(len_list, 0.01 * PADDING_PERCENTILE))\n",
    "\n",
    "print(f'sequence-length chosen on 99th percentile: {seq_len}')\n",
    "\n",
    "pad = Pad_Seq(seq_len)\n",
    "to_tensor = transform(lambda x: torch.LongTensor(x))\n",
    "emb = transform(torch.nn.Embedding)(VOCAB_SIZE, EMB_DIM)\n",
    "nn = MyNN(\n",
    "    hidden_size=RNN_HIDDEN_SIZE,\n",
    "    decoder_hidden=DECODER_HIDDEN,\n",
    "    emb_dim=EMB_DIM,\n",
    ")\n",
    "loss_function = transform(torch.nn.CrossEntropyLoss)()\n",
    "norm = transform(torch.nn.Softmax)(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253078f5",
   "metadata": {},
   "source": [
    "Let's represent graphically the distribution of the sequence length of a subsample of our data. We choose a padding length such that we keep don't cut off 99% of our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f44279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(len_list, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b74531",
   "metadata": {},
   "source": [
    "### Building and training the model.\n",
    "\n",
    "We build now our training and infer pipelines. Let's make a quick reminder of the `padl` operators:\n",
    "- `>>`: Compose operator: $(f_1 >> f_2)(x) \\rightarrow f_2(f_1(x))$\n",
    "- `+`: Rollout operator: $(f_1 + f_2) (x) \\rightarrow (f_1(x), f_2(x))$\n",
    "- `/`: Parallel operator: $(f_1 / f_2)((x_1,x_2)) \\rightarrow (f_1(x_1), f_2(x_2))$\n",
    "- `~`: Map operator: $(~f)([x_1, ..., x_n]) \\rightarrow ([f(x_1), ..., f(x_n)]$\n",
    "- `-`: Name operator: Names a transform so that its output can be accesed by given name or the transform itself can be accessed by its name from the pipeline:  \n",
    "    - $((f_1 - \\text{'zulu'})+f_2)(x) \\rightarrow \\text{Namedtuple}(\\text{'zulu'}:f_1(x), \\text{'out_1'}:f_2(x))$\n",
    "    - $((f_1 - \\text{'zulu'})+f_2)[\\text{'zulu'}] = f_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302456bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "data_model = ( \n",
    "    same[0] \n",
    "    >> bpe \n",
    "    >> pad \n",
    "    >> ~ to_tensor  \n",
    "    >> batch\n",
    "    >> emb / identity  \n",
    "    >> nn\n",
    ")\n",
    "targets = same[1] >> batch\n",
    "model = data_model + targets >> loss_function\n",
    "\n",
    "# inference pipeline for easy human readability of the output\n",
    "infer_model = (\n",
    "    bpe\n",
    "    >> to_tensor\n",
    "    >> batch\n",
    "    >> emb\n",
    "    >> nn\n",
    "    >> norm\n",
    "    >> unbatch\n",
    "    >> classify\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c68a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the inference model\n",
    "infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b49e65",
   "metadata": {},
   "source": [
    "Below, the model is trained for 20 epochs using an Adam optimization algorithm, validating each 100 steps and saving using the `pd_save` method. \n",
    "\n",
    "`Padl` provides a built-in feature for saving a `Transform`, which is the `pd_save` method. A `Transform` inheriting `torch.nn.Module` has a default saving using the `torch` saving functionality. If other `Transform` need to save anything, like `Bpe` in this example, we need to define a way to save and load, implemented respectively in the `pre_save` and `post_load` methods. If we want to overwrite a saved `padl` model which exists at the same path, we need to set the argument `force_overwrite` to `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65048132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pd_to('cuda')\n",
    "max_accuracy = 0.\n",
    "optimizer = torch.optim.Adam(model.pd_parameters(), lr=1e-4)\n",
    "it = 0\n",
    "num_epochs = 1\n",
    "max_itr = 201\n",
    "train_batch_size = 2000\n",
    "valid_batch_size = 2000\n",
    "\n",
    "if os.path.exists('train_file.csv'):\n",
    "    os.remove('train_file.csv')\n",
    "\n",
    "if os.path.exists('valid_file.csv'):\n",
    "    os.remove('valid_file.csv')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Start epoch %d'%epoch)\n",
    "    for loss in model.train_apply(train_data, batch_size=train_batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if it % 5 == 0:\n",
    "            print(f'TRAIN iteration {it}; loss: {loss.item()}')\n",
    "            with open('train_file.csv', 'a') as f:\n",
    "                f.write(f'{loss.item()}\\n')\n",
    "        if it % 50 == 0:\n",
    "            counter = 0.\n",
    "            accuracy = 0.\n",
    "            for res, targets in model[:-1].eval_apply(valid_data, batch_size=valid_batch_size):\n",
    "                top_prob, preds = res.topk(1, dim=1)\n",
    "                correct = (preds.view(-1) == targets)\n",
    "                accuracy += torch.mean(correct.type(torch.FloatTensor))\n",
    "                counter += 1\n",
    "            accuracy = accuracy/counter\n",
    "            print(f'VALID_accuracy: {accuracy}')\n",
    "            with open('valid_file.csv', 'a') as f:\n",
    "                f.write(f'{accuracy}\\n')\n",
    "            if accuracy > max_accuracy:\n",
    "                max_accuracy = accuracy\n",
    "                print('Saving...')\n",
    "                infer_model.pd_save('sent_analysis.padl', force_overwrite=True)\n",
    "        if it == max_itr:\n",
    "            break\n",
    "        it += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18a6ae",
   "metadata": {},
   "source": [
    "Now we can load and use our trained models with  the `load` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6320664",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = padl.load('sent_analysis.padl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c060142",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.infer_apply('Padl is a powerful and super cool tool!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84d8b2",
   "metadata": {},
   "source": [
    "And that's it! This is how easy is to build, train, save and load models with `padl`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
