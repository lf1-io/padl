{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc08821",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Padl\n",
    "This notebook implements and trains a Sentiment Monitor using `padl`. First, let's make sure we have all the requirements installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bcc632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install sentencepiece\n",
    "#!pip install matplotlib\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb1698",
   "metadata": {},
   "source": [
    "We import `padl` along all the needed libraries and define some required constants for the model. From `padl` we import the elements `transform`, `batch`, `unbatch`, `same` and `identity`:\n",
    "- `transform`: Any callable class implementing `__call__` or any class inheriting `torch.nn.Module` (and implementing `forward`) can become a `Base` using the `transform` decorator. \n",
    "\n",
    "- `batch`: Stands for `padl.transforms.Batchify`, which determines where the dataloader is called, and the batchs are created sent to the gpu.\n",
    "\n",
    "- `unbatch`: Stands for `padl.transforms.Unbatchify`, which unbatches the output of the neural network and indicates the beginning of the postprocess stage, carried out on the cpu.\n",
    "\n",
    "- `same`: Operator for calling methods or attributes of the object passed through it. For example: `same.count(5)([5, 7, 8, 5, 5) # outputs 3`\n",
    "\n",
    "- `identity`: Stands for `padl.transforms.Identity()`, which is the Identity transform.\n",
    "\n",
    "For our model we will also use the some global variables: `VOCAB_SIZE`, `TRAIN_TEST_SPLIT`, `EMB_DIM`, `RNN_HIDDEN_SIZE`, `DECODER_HIDDEN`, `PADDING_PERCENTILE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f5ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import uuid\n",
    "import numpy\n",
    "import pandas\n",
    "import sentencepiece\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import padl\n",
    "from padl import transform, batch, unbatch, same, identity\n",
    "\n",
    "VOCAB_SIZE = 5000 # Size of the vocabulary used by our tokenizer  \n",
    "TRAIN_TEST_SPLIT = 10000 # Number of components of each embedding vector\n",
    "EMB_DIM = 64 # Number of components of each embedding vector\n",
    "RNN_HIDDEN_SIZE = 1024 # Hidden size of our recurrent layer\n",
    "DECODER_HIDDEN = 64 # Number of hidden dimensions in the dense layers after the rnn\n",
    "PADDING_PERCENTILE = 99 # Percentile of datapoints at which we want to truncate our padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b4c00",
   "metadata": {},
   "source": [
    "### The data\n",
    "The dataset used in this notebook is `Sentiment140`, which contains 1.6 million of tweets classified as negative (0) or positive (4). The dataset can be download from kaggle:\n",
    "\n",
    "https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "We rename the file to `data.csv`, we shuffle it and subsample the 10% of it to train faster along that data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca88ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\n",
    "    'data.csv',\n",
    "    header=None,\n",
    "    sep=',',\n",
    ").sample(frac=0.1, random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4154e",
   "metadata": {},
   "source": [
    "Let's check out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facedc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2204444171</td>\n",
       "      <td>Wed Jun 17 02:14:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>einmensch</td>\n",
       "      <td>wants to compete! i want hard competition! i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017152437</td>\n",
       "      <td>Wed Jun 03 07:56:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>keithmorrison</td>\n",
       "      <td>It seems we are stuck on the ground in Amarill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1967043408</td>\n",
       "      <td>Fri May 29 18:52:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PunkieDory</td>\n",
       "      <td>where the f are my pinking shears? rarararrrar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2208721054</td>\n",
       "      <td>Wed Jun 17 09:32:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DYkEY_tYPE</td>\n",
       "      <td>0ff t0 tHE MEEtiN..  i HAtE WhEN PPl V0lUNtEER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018731586</td>\n",
       "      <td>Wed Jun 03 10:25:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BlueSmartiies</td>\n",
       "      <td>@ reply me pls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2295875426</td>\n",
       "      <td>Tue Jun 23 08:29:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>abtony</td>\n",
       "      <td>@bharathy_99: Jazz in India is just Honda stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1965198843</td>\n",
       "      <td>Fri May 29 15:30:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alitheoctopus</td>\n",
       "      <td>aaaaaaaaaaah, met a boy. he seems nice. im hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2051339641</td>\n",
       "      <td>Fri Jun 05 21:42:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RooookieP</td>\n",
       "      <td>@jonasbrothers http://twitpic.com/6q1om - Spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1969949901</td>\n",
       "      <td>Sat May 30 01:51:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>namakemono49</td>\n",
       "      <td>@saragarth Not bad, bit grumpy cause of exams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1694969873</td>\n",
       "      <td>Mon May 04 04:46:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Exercise999</td>\n",
       "      <td>@luke_redroot can't watch it  what is it?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3              4  \\\n",
       "0  0  2204444171  Wed Jun 17 02:14:00 PDT 2009  NO_QUERY      einmensch   \n",
       "1  0  2017152437  Wed Jun 03 07:56:34 PDT 2009  NO_QUERY  keithmorrison   \n",
       "2  0  1967043408  Fri May 29 18:52:13 PDT 2009  NO_QUERY     PunkieDory   \n",
       "3  0  2208721054  Wed Jun 17 09:32:48 PDT 2009  NO_QUERY     DYkEY_tYPE   \n",
       "4  4  2018731586  Wed Jun 03 10:25:27 PDT 2009  NO_QUERY  BlueSmartiies   \n",
       "5  0  2295875426  Tue Jun 23 08:29:12 PDT 2009  NO_QUERY         abtony   \n",
       "6  4  1965198843  Fri May 29 15:30:08 PDT 2009  NO_QUERY  alitheoctopus   \n",
       "7  4  2051339641  Fri Jun 05 21:42:52 PDT 2009  NO_QUERY      RooookieP   \n",
       "8  4  1969949901  Sat May 30 01:51:05 PDT 2009  NO_QUERY   namakemono49   \n",
       "9  0  1694969873  Mon May 04 04:46:43 PDT 2009  NO_QUERY    Exercise999   \n",
       "\n",
       "                                                   5  \n",
       "0  wants to compete! i want hard competition! i w...  \n",
       "1  It seems we are stuck on the ground in Amarill...  \n",
       "2  where the f are my pinking shears? rarararrrar...  \n",
       "3  0ff t0 tHE MEEtiN..  i HAtE WhEN PPl V0lUNtEER...  \n",
       "4                                    @ reply me pls   \n",
       "5  @bharathy_99: Jazz in India is just Honda stra...  \n",
       "6  aaaaaaaaaaah, met a boy. he seems nice. im hap...  \n",
       "7  @jonasbrothers http://twitpic.com/6q1om - Spor...  \n",
       "8  @saragarth Not bad, bit grumpy cause of exams ...  \n",
       "9          @luke_redroot can't watch it  what is it?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be422b8",
   "metadata": {},
   "source": [
    "We only need the first (label) and the last (text) columns. We keep, rename them and split in train and valid sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b195cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=[1, 2, 3, 4], axis=1).rename(columns={0: 'label', 5: 'text'})\n",
    "data['label'] = data['label'].apply(lambda x: int(x/4))\n",
    "data_list = list(zip(data['text'], data['label']))\n",
    "train_data = data_list[:-TRAIN_TEST_SPLIT]\n",
    "valid_data = data_list[-TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7403da77",
   "metadata": {},
   "source": [
    "We dump a text file with one sentence on each line that will be used for training our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd7b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'w') as f:\n",
    "    f.writelines(data['text'][:-TRAIN_TEST_SPLIT].apply(lambda x: x + '\\n').tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da9177",
   "metadata": {},
   "source": [
    "### Creating the Transforms\n",
    "It is time to proceed to define and instantiate the `Base` we are going to use in our model. With `padl` this is very easy! We write functions and classes implementing a `__call__` method or a `forward` if they  inherit `torch.nn.Module`, and we add the `@transform` decorator. Then, they will be ready to use the `padl` features like saving, composing, applying... As simple as that!\n",
    "\n",
    "We create the following ones:\n",
    "- `Bpe`: Consists of a tokenizer based on the byte pair encoding algorithm and uses the `sentencepiece` package.\n",
    "- `Pad_Seq`: Pads our sentences so they have the same sequence length and can be processed into batches. In our case, we choose a padding length at the 99th percentile of lengths of the samples.\n",
    "- `Embedding`: Our tokens embedder.\n",
    "- `MyNN`: Class containing our architecture.\n",
    "- `classify`: postprocess the output of the neural network.\n",
    "- `to_tensor`: converts the input to a `torch.Tensor`.\n",
    "- `loss_function`: loss function used on the training, which is the CrossEntropyLoss.\n",
    "- `norm`: computes probability values using a softmax function. This is used in the infer mode to get an idea of the probabilities of positiveness and negativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a696a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=corpus.txt --model_prefix=110d0265-edda-4776-b57d-c319336c1e8e --vocab_size=5000 --character_coverage=1.0 --model_type=bpe \n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: 110d0265-edda-4776-b57d-c319336c1e8e\n",
      "  model_type: BPE\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 150000 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=11069142\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=659\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 150000 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 150000\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 234894\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=211861 min_freq=198\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=65098 size=20 all=7429 active=2307 piece=or\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37552 size=40 all=9164 active=4042 piece=ow\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24301 size=60 all=11162 active=6039 piece=as\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17488 size=80 all=12879 active=7756 piece=!!\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14183 size=100 all=14689 active=9566 piece=all\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14070 min_freq=975\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11842 size=120 all=16786 active=2936 piece=day\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9300 size=140 all=18096 active=4246 piece=ry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8146 size=160 all=19958 active=6108 piece=ast\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6957 size=180 all=21673 active=7823 piece=nt\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6166 size=200 all=23685 active=9834 piece=▁J\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6163 min_freq=693\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5691 size=220 all=25261 active=2687 piece=ag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5066 size=240 all=27265 active=4690 piece=▁aw\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4618 size=260 all=29292 active=6717 piece=ice\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4241 size=280 all=30264 active=7689 piece=te\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3915 size=300 all=31728 active=9152 piece=▁home\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3876 min_freq=433\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3438 size=320 all=33416 active=3261 piece=▁U\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3255 size=340 all=34717 active=4562 piece=ive\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3015 size=360 all=35727 active=5572 piece=▁then\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2751 size=380 all=37220 active=7065 piece=up\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2609 size=400 all=39146 active=8989 piece=▁Just\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2605 min_freq=317\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2440 size=420 all=40200 active=3006 piece=▁thing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2339 size=440 all=42004 active=4810 piece=▁tr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2175 size=460 all=42904 active=5710 piece=ase\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2047 size=480 all=44052 active=6857 piece=▁after\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1942 size=500 all=45223 active=8028 piece=▁gonna\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1941 min_freq=259\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1845 size=520 all=46451 active=3489 piece=▁:\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1773 size=540 all=47522 active=4560 piece=▁weekend\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1680 size=560 all=48580 active=5618 piece=▁V\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1605 size=580 all=49870 active=6908 piece=▁Oh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1519 size=600 all=51402 active=8439 piece=▁wr\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1519 min_freq=210\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1448 size=620 all=52647 active=3797 piece=ix\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1407 size=640 all=53479 active=4629 piece=▁doing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1342 size=660 all=54477 active=5627 piece=▁ur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1287 size=680 all=55188 active=6338 piece=gg\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1251 size=700 all=56332 active=7482 piece=act\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1249 min_freq=181\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1214 size=720 all=57295 active=3694 piece=▁list\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1169 size=740 all=58399 active=4798 piece=▁where\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1136 size=760 all=59725 active=6124 piece=▁What\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1089 size=780 all=61063 active=7462 piece=▁into\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1055 size=800 all=62167 active=8566 piece=▁pretty\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1051 min_freq=157\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1010 size=820 all=63219 active=4158 piece=▁hey\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=980 size=840 all=63676 active=4614 piece=▁amazing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=953 size=860 all=64330 active=5268 piece=▁coming\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=934 size=880 all=65333 active=6269 piece=ank\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=899 size=900 all=66433 active=7369 piece=gr\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=897 min_freq=138\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=867 size=920 all=67729 active=4449 piece=▁Ch\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=837 size=940 all=68186 active=4906 piece=ory\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=815 size=960 all=69142 active=5862 piece=ton\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=802 size=980 all=69915 active=6635 piece=haha\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=779 size=1000 all=70528 active=7248 piece=▁music\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=776 min_freq=126\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=759 size=1020 all=71438 active=4426 piece=▁Love\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=739 size=1040 all=72735 active=5723 piece=▁world\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=722 size=1060 all=73525 active=6513 piece=▁picture\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=705 size=1080 all=74601 active=7589 piece=▁gone\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=688 size=1100 all=75640 active=8628 piece=opping\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=687 min_freq=112\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=678 size=1120 all=76627 active=4742 piece=atur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=657 size=1140 all=77640 active=5755 piece=▁family\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=631 size=1160 all=78602 active=6717 piece=▁dream\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=615 size=1180 all=79406 active=7521 piece=▁Its\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=598 size=1200 all=79786 active=7901 piece=▁eve\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=598 min_freq=104\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=580 size=1220 all=80523 active=4719 piece=▁ey\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=569 size=1240 all=81116 active=5312 piece=12\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=559 size=1260 all=81893 active=6089 piece=▁sec\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=545 size=1280 all=82556 active=6752 piece=▁stupid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=531 size=1300 all=83918 active=8113 piece=▁following\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=530 min_freq=95\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=522 size=1320 all=84487 active=4765 piece=iously\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=511 size=1340 all=85392 active=5670 piece=uter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=504 size=1360 all=86001 active=6279 piece=▁eating\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=496 size=1380 all=86717 active=6994 piece=illy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=487 size=1400 all=87328 active=7605 piece=▁hurt\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=486 min_freq=88\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=477 size=1420 all=88351 active=5383 piece=▁alone\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=466 size=1440 all=89034 active=6066 piece=ual\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=458 size=1460 all=89852 active=6884 piece=▁Work\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=450 size=1480 all=90749 active=7781 piece=aught\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=443 size=1500 all=91611 active=8642 piece=▁taking\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=442 min_freq=81\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=435 size=1520 all=92112 active=5082 piece=aying\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=427 size=1540 all=92896 active=5866 piece=atter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=420 size=1560 all=93548 active=6518 piece=▁email\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=411 size=1580 all=94280 active=7250 piece=▁defin\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=401 size=1600 all=94788 active=7758 piece=gan\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=400 min_freq=76\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=394 size=1620 all=95605 active=5469 piece=of\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=386 size=1640 all=96554 active=6418 piece=▁awake\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=379 size=1660 all=96934 active=6798 piece=▁res\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=375 size=1680 all=97391 active=7255 piece=ealous\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=369 size=1700 all=98097 active=7961 piece=▁write\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=368 min_freq=72\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=363 size=1720 all=98824 active=5631 piece=cr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=358 size=1740 all=99350 active=6157 piece=▁eas\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=353 size=1760 all=99968 active=6775 piece=▁couple\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=348 size=1780 all=100451 active=7257 piece=▁near\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=342 size=1800 all=101180 active=7986 piece=▁ep\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=342 min_freq=68\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=337 size=1820 all=102005 active=5873 piece=▁Mo\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=334 size=1840 all=102589 active=6457 piece=▁sleeping\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=328 size=1860 all=102997 active=6865 piece=ages\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=323 size=1880 all=103743 active=7611 piece=▁Your\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=317 size=1900 all=104150 active=8018 piece=HH\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=317 min_freq=64\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=312 size=1920 all=105040 active=6070 piece=▁town\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=308 size=1940 all=105773 active=6803 piece=▁broken\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=303 size=1960 all=106254 active=7284 piece=▁means\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=299 size=1980 all=106902 active=7932 piece=arr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=295 size=2000 all=107655 active=8685 piece=orld\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=295 min_freq=60\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=290 size=2020 all=108308 active=6011 piece=▁Tw\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=284 size=2040 all=108667 active=6370 piece=ls\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=280 size=2060 all=109200 active=6902 piece=que\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=277 size=2080 all=109732 active=7434 piece=andom\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=273 size=2100 all=110394 active=8096 piece=elt\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=273 min_freq=58\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=269 size=2120 all=110971 active=6051 piece=raph\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=265 size=2140 all=111842 active=6922 piece=▁bag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=263 size=2160 all=112153 active=7233 piece=▁sunshine\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=259 size=2180 all=112656 active=7736 piece=ears\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=255 size=2200 all=113323 active=8403 piece=nic\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=255 min_freq=55\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=251 size=2220 all=113959 active=6240 piece=will\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=247 size=2240 all=114667 active=6948 piece=▁flu\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=243 size=2260 all=115072 active=7353 piece=Bl\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=241 size=2280 all=115614 active=7894 piece=).\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=239 size=2300 all=116141 active=8421 piece=▁saturday\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=238 min_freq=53\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=235 size=2320 all=116643 active=6307 piece=Sp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=233 size=2340 all=117198 active=6862 piece=tweet\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=230 size=2360 all=117810 active=7474 piece=........\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=227 size=2380 all=118534 active=8198 piece=▁block\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=224 size=2400 all=119249 active=8913 piece=▁hu\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=224 min_freq=50\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=222 size=2420 all=119556 active=6254 piece=21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=220 size=2440 all=120049 active=6747 piece=amb\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=218 size=2460 all=120721 active=7419 piece=ichael\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=216 size=2480 all=121245 active=7943 piece=▁roll\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=213 size=2500 all=121512 active=8210 piece=▁ma\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=213 min_freq=48\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=211 size=2520 all=122168 active=6700 piece=▁ner\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=210 size=2540 all=122751 active=7283 piece=▁exact\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=208 size=2560 all=123529 active=8061 piece=ari\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=206 size=2580 all=124158 active=8690 piece=▁front\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=203 size=2600 all=124697 active=9229 piece=ini\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=203 min_freq=46\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=201 size=2620 all=125256 active=6714 piece=▁ref\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=199 size=2640 all=125734 active=7192 piece=▁remind\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=196 size=2660 all=126187 active=7645 piece=ees\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=195 size=2680 all=127010 active=8468 piece=▁cake\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=193 size=2700 all=127369 active=8827 piece=▁realized\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=192 min_freq=44\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=191 size=2720 all=127867 active=6867 piece=▁nights\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=189 size=2740 all=128490 active=7490 piece=▁pub\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=187 size=2760 all=129004 active=8004 piece=▁photo\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=185 size=2780 all=129201 active=8201 piece=▁along\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=183 size=2800 all=129719 active=8719 piece=▁Working\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=182 min_freq=42\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=181 size=2820 all=130368 active=7135 piece=▁vers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=179 size=2840 all=130926 active=7693 piece=uin\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=178 size=2860 all=131389 active=8156 piece=▁hanging\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=176 size=2880 all=131879 active=8646 piece=▁film\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=174 size=2900 all=132511 active=9278 piece=▁Rob\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=174 min_freq=41\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=172 size=2920 all=132990 active=7090 piece=You\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=2940 all=133413 active=7512 piece=mend\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=169 size=2960 all=133812 active=7911 piece=mom\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=168 size=2980 all=134289 active=8388 piece=▁mins\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=166 size=3000 all=134583 active=8682 piece=▁gorgeous\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=165 min_freq=39\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=163 size=3020 all=134942 active=7089 piece=▁:'\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=162 size=3040 all=135421 active=7568 piece=iant\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=161 size=3060 all=135975 active=8122 piece=mus\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=159 size=3080 all=136421 active=8568 piece=ESS\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=158 size=3100 all=136956 active=9102 piece=ther\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=158 min_freq=38\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=3120 all=137185 active=7033 piece=▁between\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=156 size=3140 all=137676 active=7524 piece=▁swimming\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=154 size=3160 all=138138 active=7986 piece=sss\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=153 size=3180 all=138447 active=8295 piece=▁share\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=151 size=3200 all=139090 active=8938 piece=itch\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=151 min_freq=37\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=150 size=3220 all=139476 active=7280 piece=ustin\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=149 size=3240 all=139799 active=7603 piece=▁Head\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=147 size=3260 all=140247 active=8050 piece=bie\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=146 size=3280 all=140541 active=8344 piece=▁cousin\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=144 size=3300 all=141152 active=8955 piece=▁13\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=144 min_freq=36\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=143 size=3320 all=141437 active=7324 piece=▁Amer\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=141 size=3340 all=141648 active=7535 piece=OP\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=140 size=3360 all=142168 active=8053 piece=Sha\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=139 size=3380 all=142807 active=8692 piece=▁Fun\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=138 size=3400 all=143157 active=9041 piece=▁Went\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=138 min_freq=35\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=136 size=3420 all=143332 active=7331 piece=fox\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=135 size=3440 all=143811 active=7810 piece=▁fixed\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=134 size=3460 all=144264 active=8263 piece=ergy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=133 size=3480 all=144460 active=8459 piece=cho\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=132 size=3500 all=144814 active=8813 piece=▁́\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=132 min_freq=34\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=131 size=3520 all=145234 active=7661 piece=Qu\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=131 size=3540 all=145592 active=8019 piece=▁window\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=130 size=3560 all=146142 active=8569 piece=▁mouth\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=129 size=3580 all=146460 active=8886 piece=▁father\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=128 size=3600 all=146888 active=9314 piece=▁mall\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=128 min_freq=33\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=127 size=3620 all=147121 active=7570 piece=than\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=3640 all=147687 active=8136 piece=yrus\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=125 size=3660 all=148080 active=8529 piece=▁cud\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=124 size=3680 all=148567 active=9016 piece=▁doc\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=123 size=3700 all=148811 active=9260 piece=Jay\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=123 min_freq=32\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=123 size=3720 all=149389 active=7951 piece=▁gosh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=122 size=3740 all=149668 active=8230 piece=▁ache\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=121 size=3760 all=149950 active=8512 piece=▁Lost\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=120 size=3780 all=150173 active=8735 piece=eff\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=3800 all=150489 active=9051 piece=edy\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=119 min_freq=31\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=118 size=3820 all=150816 active=7831 piece=▁cd\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=3840 all=151161 active=8176 piece=ko\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=117 size=3860 all=151719 active=8734 piece=▁review\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=116 size=3880 all=152095 active=9110 piece=▁egg\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=115 size=3900 all=152473 active=9488 piece=▁1.\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=115 min_freq=30\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=114 size=3920 all=152976 active=8109 piece=odes\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=113 size=3940 all=153266 active=8399 piece=kar\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=3960 all=153595 active=8728 piece=01\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=3980 all=154162 active=9295 piece=▁paid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=111 size=4000 all=154539 active=9672 piece=▁level\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=111 min_freq=29\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=110 size=4020 all=154879 active=8066 piece=entr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=110 size=4040 all=155121 active=8307 piece=quarespace\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=109 size=4060 all=155595 active=8781 piece=itchen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=108 size=4080 all=155966 active=9151 piece=▁Hehe\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=107 size=4100 all=156360 active=9545 piece=▁ny\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=107 min_freq=29\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106 size=4120 all=156709 active=8147 piece=bel\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=105 size=4140 all=157085 active=8523 piece=ua\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=105 size=4160 all=157616 active=9054 piece=▁french\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=104 size=4180 all=158038 active=9476 piece=▁phys\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=103 size=4200 all=158238 active=9676 piece=▁mi\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=103 min_freq=28\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=103 size=4220 all=158345 active=8010 piece=▁hehehe\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=102 size=4240 all=158690 active=8355 piece=▁code\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=101 size=4260 all=158982 active=8647 piece=resh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=101 size=4280 all=159187 active=8852 piece=squarespace\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=100 size=4300 all=159680 active=9345 piece=▁drama\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=100 min_freq=27\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=99 size=4320 all=160123 active=8427 piece=alif\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: 110d0265-edda-4776-b57d-c319336c1e8e.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: 110d0265-edda-4776-b57d-c319336c1e8e.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence-length chosen on 99th percentile: 52\n"
     ]
    }
   ],
   "source": [
    "@transform\n",
    "class Bpe:\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        self.vocab_size = None\n",
    "        self.dic = None\n",
    "        self.model_prefix = str(uuid.uuid4())\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self._model.encode_as_ids(x)\n",
    "    \n",
    "    def fit(self, corpus_file):\n",
    "        sentencepiece.SentencePieceTrainer.Train(\n",
    "            f'--input={corpus_file} '\n",
    "            f'--model_prefix={self.model_prefix} '\n",
    "            f'--vocab_size={VOCAB_SIZE} '\n",
    "            f'--character_coverage={1.0} '\n",
    "            '--model_type=bpe '\n",
    "        )\n",
    "        self._model = sentencepiece.SentencePieceProcessor()\n",
    "        self._model.Load(f'{self.model_prefix}.model')\n",
    "        self.vocab_size = self._model.vocab_size()\n",
    "        self.dic = {i:self._model.decode([i]) for i in range(self.vocab_size)}\n",
    "        with open(f'{self.model_prefix}.model', 'rb') as f:\n",
    "            self._content = f.read()\n",
    "        os.remove(f'{self.model_prefix}.model')\n",
    "        os.remove(f'{self.model_prefix}.vocab')\n",
    "    \n",
    "    def post_load(self, path, i):\n",
    "        self._model = sentencepiece.SentencePieceProcessor()\n",
    "        self._model.Load(str(path / f'{i}.model'))\n",
    "    \n",
    "    def pre_save(self, path, i):\n",
    "        with open(path / f'{i}.model', 'wb') as f:\n",
    "            f.write(self._content)\n",
    "\n",
    "    \n",
    "@transform\n",
    "class Pad_Seq:\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def __call__(self, seq):\n",
    "        if len(seq) < self.seq_len:\n",
    "            return seq + [2 for i in range(len(seq), self.seq_len)], [len(seq)]\n",
    "        return seq[:self.seq_len], [self.seq_len] \n",
    "\n",
    "    \n",
    "@transform\n",
    "class MyNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, decoder_hidden, emb_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=self.hidden_size, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.lin1 = torch.nn.Linear(self.hidden_size, self.decoder_hidden)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.lin2 = torch.nn.Linear(self.decoder_hidden, 2)\n",
    "    \n",
    "    def forward(self, x, lengths=None):\n",
    "        out, state = self.lstm(x)\n",
    "        if self.pd_mode != 'infer':\n",
    "            output = [sentence[length.item() - 1 , :] for sentence, length in zip(out, lengths)]\n",
    "            output = torch.stack(output)\n",
    "        if self.pd_mode == 'infer':\n",
    "            output = state[0].squeeze(0)\n",
    "        dec = self.lin1(output)\n",
    "        dec = self.act(dec)\n",
    "        return self.lin2(dec)\n",
    "    \n",
    "\n",
    "@transform\n",
    "def classify(x):\n",
    "    negative_score = x[0].item()\n",
    "    positive_score = x[1].item()\n",
    "    if positive_score > 0.6:\n",
    "        category = 'Positive'\n",
    "    elif 0.4 < positive_score <= 0.6:\n",
    "        category = 'Neutral'\n",
    "    elif 0.4 <= positive_score:\n",
    "        category = 'Negative'\n",
    "    return {'Negativeness': round(negative_score, 2),\n",
    "            'Positiveness': round(positive_score, 2), 'Sentiment': category}\n",
    "\n",
    "bpe = Bpe()\n",
    "bpe.fit('corpus.txt')\n",
    "\n",
    "random_sample = [train_data[i][0] for i in numpy.random.permutation(len(train_data))[:10000]]\n",
    "len_list = [len(bpe(sent)) for sent in random_sample]\n",
    "seq_len = int(numpy.quantile(len_list, 0.01 * PADDING_PERCENTILE))\n",
    "\n",
    "print(f'sequence-length chosen on 99th percentile: {seq_len}')\n",
    "\n",
    "pad = Pad_Seq(seq_len)\n",
    "to_tensor = transform(lambda x: torch.LongTensor(x))\n",
    "emb = transform(torch.nn.Embedding)(VOCAB_SIZE, EMB_DIM)\n",
    "nn = MyNN(\n",
    "    hidden_size=RNN_HIDDEN_SIZE,\n",
    "    decoder_hidden=DECODER_HIDDEN,\n",
    "    emb_dim=EMB_DIM,\n",
    ")\n",
    "loss_function = transform(torch.nn.CrossEntropyLoss)()\n",
    "norm = transform(torch.nn.Softmax)(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253078f5",
   "metadata": {},
   "source": [
    "Let's represent graphically the distribution of the sequence length of a subsample of our data. As we see, with out padding to a sequence length of 52 we keep the 99% of our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f44279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.600e+02, 1.178e+03, 1.675e+03, 1.546e+03, 1.333e+03, 1.152e+03,\n",
       "        1.037e+03, 8.310e+02, 5.540e+02, 2.140e+02, 7.800e+01, 2.200e+01,\n",
       "        8.000e+00, 4.000e+00, 3.000e+00, 1.000e+00, 2.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([  1.  ,   5.95,  10.9 ,  15.85,  20.8 ,  25.75,  30.7 ,  35.65,\n",
       "         40.6 ,  45.55,  50.5 ,  55.45,  60.4 ,  65.35,  70.3 ,  75.25,\n",
       "         80.2 ,  85.15,  90.1 ,  95.05, 100.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAATZUlEQVR4nO3df6xf9X3f8edrdiEl3WJ+3DJiW7te46ai0bKgO0KVrUtDRwxENX+kEawbbmbJ2kbatImWmFYaWqtIzlaFBi1D8sDFTBmEUlaswMpcQocmDcKFpIRfKbeE4GtBfFN+tGvUEDfv/fH9ePvm4mv73u/9Yd/P8yFdfc95n8/3ez4fHet1jz/fc89JVSFJ6sPfWOkOSJKWj6EvSR0x9CWpI4a+JHXE0Jekjqxd6Q4cyznnnFPj4+Mr3Q1JOqU8+uij366qsaNtO6lDf3x8nMnJyZXuhiSdUpJ8c65tTu9IUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHTuq/yD1Vje+8Z8HvfX7X5YvYE0n6QZ7pS1JHDH1J6oihL0kdMfQlqSOGviR15Lihn2RPkkNJnphV/6UkzyR5Msm/H6pfm2QqydeTvH+ovqXVppLsXNxhSJJOxIlcsnkL8B+BW48UkvwMsBV4Z1V9N8mPtvr5wJXATwJvBf4wyY+3t30O+CfANPBIkn1V9dRiDUSSdHzHDf2qejDJ+KzyvwJ2VdV3W5tDrb4VuL3Vv5FkCriwbZuqqucAktze2hr6krSMFjqn/+PAP0rycJL/meQftPp64MBQu+lWm6v+Bkl2JJlMMjkzM7PA7kmSjmahob8WOAu4CPg3wB1JshgdqqrdVTVRVRNjY0d9rq8kaYEWehuGaeCuqirgy0m+D5wDHAQ2DrXb0Gocoy5JWiYLPdP/feBnANoXtacB3wb2AVcmOT3JJmAz8GXgEWBzkk1JTmPwZe++EfsuSZqn457pJ7kNeC9wTpJp4DpgD7CnXcb5OrCtnfU/meQOBl/QHgauqaq/bp/zEeA+YA2wp6qeXILxSJKO4USu3rlqjk3/bI72nwI+dZT6vcC98+qdJGlR+Re5ktQR76d/khnlXvzg/fglHZtn+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI8cN/SR7khxqT8mave3jSSrJOW09SW5IMpXk8SQXDLXdluTZ9rNtcYchSToRJ3KmfwuwZXYxyUbgEuCFofKlDJ6LuxnYAdzY2p7F4DGL7wYuBK5LcuYoHZckzd9xQ7+qHgRePsqm64FPADVU2wrcWgMPAeuSnAe8H9hfVS9X1SvAfo7yi0SStLQWNKefZCtwsKr+eNam9cCBofXpVpurfrTP3pFkMsnkzMzMQronSZrDvEM/yRnArwH/dvG7A1W1u6omqmpibGxsKXYhSd1ayJn+jwGbgD9O8jywAXgsyd8GDgIbh9puaLW56pKkZTTv0K+qr1XVj1bVeFWNM5iquaCqXgL2AVe3q3guAl6rqheB+4BLkpzZvsC9pNUkScvoRC7ZvA3438Dbk0wn2X6M5vcCzwFTwH8G/jVAVb0M/CbwSPv5jVaTJC2jtcdrUFVXHWf7+NByAdfM0W4PsGee/ZMkLSL/IleSOmLoS1JHjju9o1PL+M57Fvze53ddvog9kXQy8kxfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR05kYeo7ElyKMkTQ7X/kOSZJI8n+W9J1g1tuzbJVJKvJ3n/UH1Lq00l2bnoI5EkHdeJnOnfAmyZVdsPvKOq/h7wJ8C1AEnOB64EfrK95z8lWZNkDfA54FLgfOCq1laStIyOG/pV9SDw8qza/6iqw231IQYPOgfYCtxeVd+tqm8weGzihe1nqqqeq6rXgdtbW0nSMlqMOf1/Afz3trweODC0bbrV5qq/QZIdSSaTTM7MzCxC9yRJR4wU+kl+HTgMfH5xugNVtbuqJqpqYmxsbLE+VpLECE/OSvKLwAeAi9sD0QEOAhuHmm1oNY5RlyQtkwWFfpItwCeAf1xV3xnatA/4r0k+A7wV2Ax8GQiwOckmBmF/JfBPR+n4UhvlsYOSdLI6bugnuQ14L3BOkmngOgZX65wO7E8C8FBV/cuqejLJHcBTDKZ9rqmqv26f8xHgPmANsKeqnlyC8UiSjuG4oV9VVx2lfPMx2n8K+NRR6vcC986rd5KkRbXgOX2tPqNMaT2/6/JF7ImkpeJtGCSpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR7y1shaFt2WWTg3HPdNPsifJoSRPDNXOSrI/ybPt9cxWT5IbkkwleTzJBUPv2dbaP5tk29IMR5J0LCcyvXMLsGVWbSdwf1VtBu5v6wCXMngu7mZgB3AjDH5JMHjM4ruBC4HrjvyikCQtn+OGflU9CLw8q7wV2NuW9wJXDNVvrYGHgHVJzgPeD+yvqper6hVgP2/8RSJJWmIL/SL33Kp6sS2/BJzbltcDB4baTbfaXPU3SLIjyWSSyZmZmQV2T5J0NCNfvVNVBdQi9OXI5+2uqomqmhgbG1usj5UksfDQ/1abtqG9Hmr1g8DGoXYbWm2uuiRpGS009PcBR67A2QbcPVS/ul3FcxHwWpsGug+4JMmZ7QvcS1pNkrSMjnudfpLbgPcC5ySZZnAVzi7gjiTbgW8CH2rN7wUuA6aA7wAfBqiql5P8JvBIa/cbVTX7y2FJ0hI7buhX1VVzbLr4KG0LuGaOz9kD7JlX7yRJi8rbMEhSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSR495PX1pq4zvvWfB7n991+SL2RFr9RjrTT/KrSZ5M8kSS25K8KcmmJA8nmUryhSSntbant/Wptn18UUYgSTphCw79JOuBXwYmquodwBrgSuDTwPVV9TbgFWB7e8t24JVWv761kyQto1Hn9NcCP5xkLXAG8CLwPuDOtn0vcEVb3trWadsvTpIR9y9JmocFh35VHQR+C3iBQdi/BjwKvFpVh1uzaWB9W14PHGjvPdzanz37c5PsSDKZZHJmZmah3ZMkHcUo0ztnMjh73wS8FXgzsGXUDlXV7qqaqKqJsbGxUT9OkjRklOmdnwW+UVUzVfU94C7gPcC6Nt0DsAE42JYPAhsB2va3AH82wv4lSfM0Sui/AFyU5Iw2N38x8BTwAPDB1mYbcHdb3tfWadu/VFU1wv4lSfM0ypz+wwy+kH0M+Fr7rN3AJ4GPJZliMGd/c3vLzcDZrf4xYOcI/ZYkLcBIf5xVVdcB180qPwdceJS2fwX8/Cj7kySNxtswSFJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGRQj/JuiR3JnkmydNJfirJWUn2J3m2vZ7Z2ibJDUmmkjye5ILFGYIk6USNeqb/WeAPquongHcCTzN4Itb9VbUZuJ///4SsS4HN7WcHcOOI+5YkzdOCQz/JW4Cfpj0Osaper6pXga3A3tZsL3BFW94K3FoDDzF4gPp5C92/JGn+RjnT3wTMAL+T5CtJbkryZuDcqnqxtXkJOLctrwcODL1/utUkSctklNBfC1wA3FhV7wL+klkPO6+qAmo+H5pkR5LJJJMzMzMjdE+SNNsooT8NTFfVw239Tga/BL51ZNqmvR5q2w8CG4fev6HVfkBV7a6qiaqaGBsbG6F7kqTZFhz6VfUScCDJ21vpYuApYB+wrdW2AXe35X3A1e0qnouA14amgSRJy2DtiO//JeDzSU4DngM+zOAXyR1JtgPfBD7U2t4LXAZMAd9pbSVJy2ik0K+qrwITR9l08VHaFnDNKPuTJI1m1DN9aUWN77xnpPc/v+vyReqJdGrwNgyS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZOTQT7ImyVeSfLGtb0rycJKpJF9oT9UiyeltfaptHx9135Kk+VmMM/2PAk8PrX8auL6q3ga8Amxv9e3AK61+fWsnSVpGI4V+kg3A5cBNbT3A+4A7W5O9wBVteWtbp22/uLWXJC2TUc/0fxv4BPD9tn428GpVHW7r08D6trweOADQtr/W2v+AJDuSTCaZnJmZGbF7kqRhCw79JB8ADlXVo4vYH6pqd1VNVNXE2NjYYn60JHVvlAejvwf4uSSXAW8C/hbwWWBdkrXtbH4DcLC1PwhsBKaTrAXeAvzZCPuXJM3Tgs/0q+raqtpQVePAlcCXquoXgAeAD7Zm24C72/K+tk7b/qWqqoXuX5I0f0txnf4ngY8lmWIwZ39zq98MnN3qHwN2LsG+JUnHMMr0zv9TVX8E/FFbfg648Cht/gr4+cXY34ka33nPcu5Okk56/kWuJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjozwYfWOSB5I8leTJJB9t9bOS7E/ybHs9s9WT5IYkU0keT3LBYg1CknRiRnly1mHg41X1WJK/CTyaZD/wi8D9VbUryU4Gj0X8JHApsLn9vBu4sb1KK2aUp6s9v+vyReyJtDxGeTD6i1X1WFv+C+BpYD2wFdjbmu0FrmjLW4Fba+AhYF2S8xa6f0nS/C3KnH6SceBdwMPAuVX1Ytv0EnBuW14PHBh623Srzf6sHUkmk0zOzMwsRvckSc3IoZ/kR4DfA36lqv58eFtVFVDz+byq2l1VE1U1MTY2Nmr3JElDRgr9JD/EIPA/X1V3tfK3jkzbtNdDrX4Q2Dj09g2tJklaJqNcvRPgZuDpqvrM0KZ9wLa2vA24e6h+dbuK5yLgtaFpIEnSMhjl6p33AP8c+FqSr7barwG7gDuSbAe+CXyobbsXuAyYAr4DfHiEfUuSFmDBoV9V/wvIHJsvPkr7Aq5Z6P4kSaPzL3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjo9yGQeqaD2DRqcgzfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRZb9kM8kW4LPAGuCmqtq13H2QVpqXe2qlLOuZfpI1wOeAS4HzgauSnL+cfZCkni33mf6FwFRVPQeQ5HZgK/DUMvdDOmWN8r+EleT/UE4Oyx3664EDQ+vTwLuHGyTZAexoq/8nydfnuY9zgG8vuIenph7HDH2O+5Qdcz490ttP2XGPYJQx/525Npx0t2Goqt3A7oW+P8lkVU0sYpdOej2OGfocd49jhj7HvVRjXu6rdw4CG4fWN7SaJGkZLHfoPwJsTrIpyWnAlcC+Ze6DJHVrWad3qupwko8A9zG4ZHNPVT25yLtZ8NTQKazHMUOf4+5xzNDnuJdkzKmqpfhcSdJJyL/IlaSOGPqS1JFVE/pJtiT5epKpJDtXuj9LJcnGJA8keSrJk0k+2upnJdmf5Nn2euZK93WxJVmT5CtJvtjWNyV5uB3zL7SLA1aNJOuS3JnkmSRPJ/mpTo7zr7Z/208kuS3Jm1bjsU6yJ8mhJE8M1Y56fDNwQxv/40kuWOh+V0Xod3Z7h8PAx6vqfOAi4Jo21p3A/VW1Gbi/ra82HwWeHlr/NHB9Vb0NeAXYviK9WjqfBf6gqn4CeCeDsa/q45xkPfDLwERVvYPBBR9XsjqP9S3Allm1uY7vpcDm9rMDuHGhO10Voc/Q7R2q6nXgyO0dVp2qerGqHmvLf8EgCNYzGO/e1mwvcMWKdHCJJNkAXA7c1NYDvA+4szVZVWNO8hbgp4GbAarq9ap6lVV+nJu1wA8nWQucAbzIKjzWVfUg8PKs8lzHdytwaw08BKxLct5C9rtaQv9ot3dYv0J9WTZJxoF3AQ8D51bVi23TS8C5K9WvJfLbwCeA77f1s4FXq+pwW19tx3wTMAP8TpvSuinJm1nlx7mqDgK/BbzAIOxfAx5ldR/rYXMd30XLuNUS+t1J8iPA7wG/UlV/PrytBtfhrpprcZN8ADhUVY+udF+W0VrgAuDGqnoX8JfMmspZbccZoM1hb2XwS++twJt54xRIF5bq+K6W0O/q9g5JfohB4H++qu5q5W8d+e9eez20Uv1bAu8Bfi7J8wym7t7HYL57XZsCgNV3zKeB6ap6uK3fyeCXwGo+zgA/C3yjqmaq6nvAXQyO/2o+1sPmOr6LlnGrJfS7ub1Dm8u+GXi6qj4ztGkfsK0tbwPuXu6+LZWquraqNlTVOINj+6Wq+gXgAeCDrdlqG/NLwIEkb2+lixncgnzVHufmBeCiJGe0f+tHxr1qj/Uscx3ffcDV7Sqei4DXhqaB5qeqVsUPcBnwJ8CfAr++0v1ZwnH+Qwb/5Xsc+Gr7uYzBHPf9wLPAHwJnrXRfl2j87wW+2Jb/LvBlYAr4XeD0le7fIo/17wOT7Vj/PnBmD8cZ+HfAM8ATwH8BTl+Nxxq4jcH3Ft9j8D+77XMdXyAMrlD8U+BrDK5uWtB+vQ2DJHVktUzvSJJOgKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOvJ/AXfOS79v9zNWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(len_list, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b74531",
   "metadata": {},
   "source": [
    "### Building and training the model.\n",
    "\n",
    "We build now our training and infer pipelines. Let's make a quick reminder of the `padl` operators:\n",
    "- `>>`: Compose operator: $(f_1 >> f_2)(x) \\rightarrow f_2(f_1(x))$\n",
    "- `+`: Rollout operator: $(f_1 + f_2) (x) \\rightarrow (f_1(x), f_2(x))$\n",
    "- `/`: Parallel operator: $(f_1 / f_2)((x_1,x_2)) \\rightarrow (f_1(x_1), f_2(x_2))$\n",
    "- `~`: Map operator: $(~f)([x_1, ..., x_n]) \\rightarrow ([f(x_1), ..., f(x_n)]$\n",
    "- `-`: Name operator: Names a transform so that its output can be accesed by given name or the transform itself can be accessed by its name from the pipeline:  \n",
    "    - $((f_1 - \\text{'zulu'})+f_2)(x) \\rightarrow \\text{Namedtuple}(\\text{'zulu'}:f_1(x), \\text{'out_1'}:f_2(x))$\n",
    "    - $((f_1 - \\text{'zulu'})+f_2)[\\text{'zulu'}] = f_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302456bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = ( \n",
    "    same[0] \n",
    "    >> bpe \n",
    "    >> pad \n",
    "    >> ~ to_tensor  \n",
    "    >> batch\n",
    "    >> emb / identity  \n",
    "    >> nn\n",
    ")\n",
    "targets = same[1] >> batch\n",
    "model = data_model + targets >> loss_function\n",
    "\n",
    "infer_model = (\n",
    "    bpe\n",
    "    >> to_tensor\n",
    "    >> batch\n",
    "    >> emb\n",
    "    >> nn\n",
    "    >> norm\n",
    "    >> unbatch\n",
    "    >> classify\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b49e65",
   "metadata": {},
   "source": [
    "Below, the model is trained for 20 epochs using an Adam optimization algorithm, validating each 100 steps and saving using the `pd_save` method. \n",
    "\n",
    "`Padl` provides a built-in feature for saving a `Base`, which is the `pd_save` method. A `Base` inheriting `torch.nn.Module` has a default saving using the `torch` saving functionality. If other `Base` need to save anything, like `Bpe` in this example, we need to define a way to save and load, implemented respectively in the `pre_save` and `post_load` methods. If we want to overwrite a saved `padl` model which exists at the same path, we need to set the argument `force_overwrite` to `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65048132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n",
      "TRAIN iteration 0; loss: 0.6947038769721985\n",
      "VALID_accuracy: 0.4934999942779541\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 10; loss: 0.6906222105026245\n",
      "TRAIN iteration 20; loss: 0.6859002709388733\n",
      "TRAIN iteration 30; loss: 0.6752104163169861\n",
      "Start epoch 1\n",
      "TRAIN iteration 40; loss: 0.6641473174095154\n",
      "TRAIN iteration 50; loss: 0.6562404036521912\n",
      "TRAIN iteration 60; loss: 0.652820885181427\n",
      "TRAIN iteration 70; loss: 0.6427056789398193\n",
      "Start epoch 2\n",
      "TRAIN iteration 80; loss: 0.6457321643829346\n",
      "TRAIN iteration 90; loss: 0.6501889824867249\n",
      "TRAIN iteration 100; loss: 0.6404860615730286\n",
      "VALID_accuracy: 0.6357499957084656\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 110; loss: 0.6329899430274963\n",
      "Start epoch 3\n",
      "TRAIN iteration 120; loss: 0.635252058506012\n",
      "TRAIN iteration 130; loss: 0.6243354678153992\n",
      "TRAIN iteration 140; loss: 0.6225642561912537\n",
      "TRAIN iteration 150; loss: 0.6127985715866089\n",
      "Start epoch 4\n",
      "TRAIN iteration 160; loss: 0.6067519783973694\n",
      "TRAIN iteration 170; loss: 0.6153565049171448\n",
      "TRAIN iteration 180; loss: 0.5954265594482422\n",
      "Start epoch 5\n",
      "TRAIN iteration 190; loss: 0.5899824500083923\n",
      "TRAIN iteration 200; loss: 0.588318407535553\n",
      "VALID_accuracy: 0.6858333945274353\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 210; loss: 0.5769174695014954\n",
      "TRAIN iteration 220; loss: 0.574532687664032\n",
      "Start epoch 6\n",
      "TRAIN iteration 230; loss: 0.5814948678016663\n",
      "TRAIN iteration 240; loss: 0.5644465088844299\n",
      "TRAIN iteration 250; loss: 0.5725738406181335\n",
      "TRAIN iteration 260; loss: 0.5513509511947632\n",
      "Start epoch 7\n",
      "TRAIN iteration 270; loss: 0.5832719206809998\n",
      "TRAIN iteration 280; loss: 0.5667550563812256\n",
      "TRAIN iteration 290; loss: 0.5543938875198364\n",
      "TRAIN iteration 300; loss: 0.5393378138542175\n",
      "VALID_accuracy: 0.7122499942779541\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "Start epoch 8\n",
      "TRAIN iteration 310; loss: 0.5516550540924072\n",
      "TRAIN iteration 320; loss: 0.5448687076568604\n",
      "TRAIN iteration 330; loss: 0.5566322207450867\n",
      "TRAIN iteration 340; loss: 0.5291003584861755\n",
      "Start epoch 9\n",
      "TRAIN iteration 350; loss: 0.5467310547828674\n",
      "TRAIN iteration 360; loss: 0.5399101376533508\n",
      "TRAIN iteration 370; loss: 0.54032963514328\n",
      "Start epoch 10\n",
      "TRAIN iteration 380; loss: 0.5330530405044556\n",
      "TRAIN iteration 390; loss: 0.5297200679779053\n",
      "TRAIN iteration 400; loss: 0.5232966542243958\n",
      "VALID_accuracy: 0.7289166450500488\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 410; loss: 0.5260593295097351\n",
      "Start epoch 11\n",
      "TRAIN iteration 420; loss: 0.5320862531661987\n",
      "TRAIN iteration 430; loss: 0.5193870663642883\n",
      "TRAIN iteration 440; loss: 0.5331116318702698\n",
      "TRAIN iteration 450; loss: 0.5037891864776611\n",
      "Start epoch 12\n",
      "TRAIN iteration 460; loss: 0.5355626940727234\n",
      "TRAIN iteration 470; loss: 0.5226110219955444\n",
      "TRAIN iteration 480; loss: 0.5091677904129028\n",
      "TRAIN iteration 490; loss: 0.5088812708854675\n",
      "Start epoch 13\n",
      "TRAIN iteration 500; loss: 0.5185052156448364\n",
      "VALID_accuracy: 0.734416663646698\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 510; loss: 0.5084543824195862\n",
      "TRAIN iteration 520; loss: 0.5204645991325378\n",
      "TRAIN iteration 530; loss: 0.49525976181030273\n",
      "Start epoch 14\n",
      "TRAIN iteration 540; loss: 0.5098943710327148\n",
      "TRAIN iteration 550; loss: 0.5045745968818665\n",
      "TRAIN iteration 560; loss: 0.5006686449050903\n",
      "Start epoch 15\n",
      "TRAIN iteration 570; loss: 0.5051096677780151\n",
      "TRAIN iteration 580; loss: 0.5021302103996277\n",
      "TRAIN iteration 590; loss: 0.49500545859336853\n",
      "TRAIN iteration 600; loss: 0.5030442476272583\n",
      "VALID_accuracy: 0.7434167265892029\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "Start epoch 16\n",
      "TRAIN iteration 610; loss: 0.4948078393936157\n",
      "TRAIN iteration 620; loss: 0.49545618891716003\n",
      "TRAIN iteration 630; loss: 0.5016372799873352\n",
      "TRAIN iteration 640; loss: 0.4851166307926178\n",
      "Start epoch 17\n",
      "TRAIN iteration 650; loss: 0.5088880658149719\n",
      "TRAIN iteration 660; loss: 0.4949275553226471\n",
      "TRAIN iteration 670; loss: 0.478756308555603\n",
      "TRAIN iteration 680; loss: 0.48727765679359436\n",
      "Start epoch 18\n",
      "TRAIN iteration 690; loss: 0.49614420533180237\n",
      "TRAIN iteration 700; loss: 0.4834238290786743\n",
      "VALID_accuracy: 0.7450833320617676\n",
      "Saving...\n",
      "saving torch module to sent_analysis.padl/sent_analysis_4.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_5.pt\n",
      "saving torch module to sent_analysis.padl/sent_analysis_6.pt\n",
      "TRAIN iteration 710; loss: 0.49662700295448303\n",
      "TRAIN iteration 720; loss: 0.4747251570224762\n",
      "Start epoch 19\n",
      "TRAIN iteration 730; loss: 0.48134317994117737\n",
      "TRAIN iteration 740; loss: 0.4802393913269043\n",
      "TRAIN iteration 750; loss: 0.4737522602081299\n"
     ]
    }
   ],
   "source": [
    "model.pd_to('cuda')\n",
    "max_accuracy = 0.\n",
    "optimizer = torch.optim.Adam(model.pd_parameters(), lr=1e-4)\n",
    "it = 0\n",
    "num_epochs = 20\n",
    "train_batch_size = 4000\n",
    "valid_batch_size = 4000\n",
    "\n",
    "if os.path.exists('train_file.csv'):\n",
    "    os.remove('train_file.csv')\n",
    "\n",
    "if os.path.exists('valid_file.csv'):\n",
    "    os.remove('valid_file.csv')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Start epoch %d'%epoch)\n",
    "    for loss in model.train_apply(train_data, batch_size=train_batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if it % 10 == 0:\n",
    "            print(f'TRAIN iteration {it}; loss: {loss.item()}')\n",
    "            with open('train_file.csv', 'a') as f:\n",
    "                f.write(f'{loss.item()}\\n')\n",
    "        if it % 100 == 0:\n",
    "            counter = 0.\n",
    "            accuracy = 0.\n",
    "            for res, targets in model[:-1].eval_apply(valid_data, batch_size=valid_batch_size):\n",
    "                top_prob, preds = res.topk(1, dim=1)\n",
    "                correct = (preds.view(-1) == targets)\n",
    "                accuracy += torch.mean(correct.type(torch.FloatTensor))\n",
    "                counter += 1\n",
    "            accuracy = accuracy/counter\n",
    "            print(f'VALID_accuracy: {accuracy}')\n",
    "            with open('valid_file.csv', 'a') as f:\n",
    "                f.write(f'{accuracy}\\n')\n",
    "            if accuracy > max_accuracy:\n",
    "                max_accuracy = accuracy\n",
    "                print('Saving...')\n",
    "                infer_model.pd_save('sent_analysis.padl', force_overwrite=True)\n",
    "        it += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18a6ae",
   "metadata": {},
   "source": [
    "Now we can load and use our trained models with  the `load` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6320664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading torch module from sent_analysis.padl/sent_analysis_4.pt\n",
      "loading torch module from sent_analysis.padl/sent_analysis_5.pt\n",
      "loading torch module from sent_analysis.padl/sent_analysis_6.pt\n"
     ]
    }
   ],
   "source": [
    "loaded_model = padl.load('sent_analysis.padl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c060142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negativeness': 0.24, 'Positiveness': 0.76, 'Sentiment': 'Positive'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.infer_apply('Padl is a powerful and super cool tool!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84d8b2",
   "metadata": {},
   "source": [
    "And that's it! This is how easy is to build, train, save and load models with `padl`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
