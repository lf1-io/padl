{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5492e1e4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may also need to install torchvision and matplotlib\n",
    "# !pip install matplotlib\n",
    "# !pip install torchvision\n",
    "# !pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d969c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "import padl\n",
    "from padl import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd944ba",
   "metadata": {},
   "source": [
    "## Using PADL with Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de455b",
   "metadata": {},
   "source": [
    "## Kaggle Digit Recognizer dataset:\n",
    "Kaggle Digit Recognizer dataset is used in this notebook. It can be easily downloaded from the kaggle link below.\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer\n",
    "\n",
    "Details on the structure of the data can be read from the link above. Important information on the data structure is given in exerpt below\n",
    "\n",
    "> The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "\n",
    "### 0. Reading `csv` files for training and testing\n",
    "Note: `test.csv` does not contain data label in kaggle dataset. It is inteded to be used for submission to kaggle competition. Here, we can use it for quick inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'mnist/train.csv'\n",
    "test_csv = 'mnist/test.csv'\n",
    "\n",
    "with open(train_csv) as f:\n",
    "    train_data = f.readlines()\n",
    "train_array = torch.tensor([list(map(int, line.split(','))) for line in train_data[1:]])\n",
    "\n",
    "train_array = train_array[:-1000]\n",
    "valid_array = train_array[-1000:]\n",
    "\n",
    "with open(test_csv) as f:\n",
    "    test_data = f.readlines()\n",
    "test_array = torch.tensor([list(map(int, line.split(','))) for line in test_data[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4df6",
   "metadata": {},
   "source": [
    "### 1. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee59c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "@transform\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv 1\n",
    "        # size : input: 28x28x1 -> output : 26 x 26 x 32\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Conv 2\n",
    "        # size : input: 26x26x32 -> output : 24 x 24 x 32\n",
    "        self.conv2 = torch.nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Conv 3\n",
    "        # size : input: 24x24x32 -> output : 12 x 12 x 32\n",
    "        self.conv3 = torch.nn.Conv2d(32, 32, kernel_size=2, stride = 2)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Conv 4\n",
    "        # size : input : 12 x 12 x 32 -> output : 8 x 8 x 64\n",
    "        self.conv4 = torch.nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.batchnorm4 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Conv 5\n",
    "        # size : input: 8x8x64 -> output : 4 x 4 x 64 -> Linearize = 1024\n",
    "        self.conv5 = torch.nn.Conv2d(64, 64, kernel_size=2, stride = 2)\n",
    "        self.batchnorm5 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.conv5_drop = torch.nn.Dropout2d()\n",
    "        \n",
    "        # FC 1 \n",
    "        self.fc1 = torch.nn.Linear(1024, 128)\n",
    "        \n",
    "        # FC 2\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(F.relu(self.conv1(x)))\n",
    "        x = self.batchnorm2(F.relu(self.conv2(x)))\n",
    "        x = self.batchnorm3(F.relu(self.conv3(x)))\n",
    "        x = self.batchnorm4(F.relu(self.conv4(x)))\n",
    "        x = self.batchnorm5(F.relu(self.conv5(x)))\n",
    "        x = self.conv5_drop(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20863e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device to be used:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1mCompose\u001b[0m:\n",
       "\n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m0: \u001b[0mtype(<class 'torch.FloatTensor'>)\n",
       "   \u001b[32m   └───────────────────────────────────┐\n",
       "      │                                   │\n",
       "      ▼ args                              ▼ args\u001b[0m\n",
       "   \u001b[1m1: \u001b[0m__getitem__(slice(1, None, None)) \u001b[32m+\u001b[0m __getitem__(0)   \n",
       "   \u001b[32m   │                                   │\n",
       "      ▼ args                              ▼ args\u001b[0m\n",
       "   \u001b[1m2: \u001b[0mreshape(-1, 28, 28)               \u001b[32m/\u001b[0m padl.Identity()  \n",
       "   \u001b[32m   │\n",
       "      ▼ args\u001b[0m\n",
       "   \u001b[1m3: \u001b[0mBatchify(dim=0)                  \n",
       "   \u001b[32m   │└──────────────────────────────────┐\n",
       "      │                                   │\n",
       "      ▼ x                                 ▼ args\u001b[0m\n",
       "   \u001b[1m4: \u001b[0mSimpleNet()                       \u001b[32m/\u001b[0m type(torch.int64)\n",
       "   \u001b[32m   │\n",
       "      ▼ (input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n",
       "   \u001b[1m5: \u001b[0mnll_loss                         "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = (\n",
    "    padl.this.type(torch.FloatTensor)\n",
    "    >> padl.this[1:] + padl.this[0]\n",
    "    >> padl.this.reshape(-1, 28, 28) / padl.Identity()\n",
    ")\n",
    "\n",
    "simplenet = SimpleNet()\n",
    "loss_func = transform(F.nll_loss)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device to be used: ', device)\n",
    "\n",
    "train_model = (\n",
    "    preprocess\n",
    "    >> padl.Batchify()\n",
    "    >> simplenet / padl.this.type(torch.long)\n",
    "    >> transform(F.nll_loss)\n",
    ")\n",
    "\n",
    "train_model.pd_to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404e855",
   "metadata": {},
   "source": [
    "### 2.1 Creating a Lightning Module using PADLLightningModule\n",
    "If your `train_model` has the loss function as the final step you can directly build the `PADLLightning` object by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from padl import PADLLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35407731",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADLLightning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = PADLLightning(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_array,  # list of training data points\n",
    "    valid_array,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de0b17",
   "metadata": {},
   "source": [
    "### 2.2 Inherit from PADLLightningModule to customize in the same way as a LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72046679",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "learning_rate = 0.01\n",
    "\n",
    "class MyModule(PADLLightning):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3f1f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "padl_lightning_module = MyModule(\n",
    "    train_model,  # train_model with the loss function\n",
    "    train_array,  # list of training data points\n",
    "    valid_array,  # list of validation data points\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd07cd",
   "metadata": {},
   "source": [
    "### 3. Training and validating the `train_model` with the PADL-Pytorch Lightning Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed2baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | layer_0 | SimpleNet | 214 K \n",
      "--------------------------------------\n",
      "214 K     Trainable params\n",
      "0         Non-trainable params\n",
      "214 K     Total params\n",
      "0.857     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb39ffbe748245d2b8c39051c5cf20d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_7/checkpoints/model.padl/model_10.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving torch module to test/lightning_logs/version_7/checkpoints/epoch=0-step=160.padl/epoch=0-step=160_10.pt\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "log_interval = 10\n",
    "nepoch = 2\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\")],\n",
    "    max_epochs=nepoch,\n",
    "    default_root_dir='test',\n",
    "    log_every_n_steps=log_interval\n",
    ")\n",
    "trainer.fit(padl_lightning_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851506c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
